{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MLPClassifier do módulo sklearn.neural_network\n",
    "\n",
    "* O principal parâmetro para um classificador de rede neural é esse parâmetro, hidden_layer_sizes.Este parâmetro é uma lista, com um elemento para cada camada oculta,  que fornece o número de unidades ocultas a serem usadas para essa camada.\n",
    "\n",
    "* O parâmetro solver especifica o algoritmo a ser usado para aprender os pesos da rede.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import os \n",
    "os.chdir(r'C:\\Users\\gizel\\Documents\\PUCMG\\PUC_MG_Disciplinas\\PUC_MG_Disciplinas\\04 - Machine Learning\\Unidade 3 - Aprendizado Supervisionado Classificação e Regressão/dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar = pd.read_excel('sonar.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rocha' 'Mina']\n"
     ]
    }
   ],
   "source": [
    "print(sonar['Classe'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# 0 para Rocha \n",
    "# 1 para Mina \n",
    "\n",
    "sonar = sonar.replace('Rocha', 0)\n",
    "sonar = sonar.replace('Mina',1)\n",
    "\n",
    "print(sonar['Classe'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dados de Teste e Dados de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pacote de treinamento: Pegando todas as colunas exceto a última coluna que possui os labels: 'Classe'\n",
    "\n",
    "X_train_ = sonar.iloc[:,0:(sonar.shape[1] - 1)]\n",
    "\n",
    "\n",
    "# LabelEnconder transforma apenas a última coluna \"Classe:['Rocha' 'Mina'] string em classe binária \n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train_ = le.fit_transform(sonar.iloc[:,(sonar.shape[1]-1)])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_, y_train_,random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construindo o modelo com duas camadas sem regularização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  on training set: 1.00\n",
      "Accuracy  on test set: 0.81\n",
      "\n",
      "\n",
      "The current loss computed with the loss function  0.0003499961380952154\n",
      "\n",
      "\n",
      "The number of iterations the solver has ran.  61\n",
      "\n",
      "\n",
      "The ith element in the list represents the bias vector corresponding to layer i + 1.  [array([ 0.09793604,  0.65933186,  0.94093143, -0.29576134,  0.05735419,\n",
      "       -0.0357136 ,  0.13961629, -0.18025247, -0.33556593,  0.15500896,\n",
      "        0.7052307 , -0.06925135,  0.93285423,  0.13957653, -0.89660265,\n",
      "        0.1759679 ,  0.11657515, -0.05689783,  0.36025893, -0.25403758,\n",
      "       -0.2490913 , -0.25656625, -0.40091914,  0.84682717, -1.41438041,\n",
      "       -0.59326604, -0.17631439, -0.13950317, -0.41923573,  0.17388008,\n",
      "       -0.05330094, -0.08532776, -0.09385319, -0.0755602 , -0.38277193,\n",
      "        1.7143912 ,  1.32733288,  0.90987366,  0.07664363,  0.00995346,\n",
      "       -0.01017292, -0.36976442, -0.01580296, -0.25115254,  0.02645054,\n",
      "        0.1124788 , -0.02372505,  0.07238137, -0.22387794, -0.36186831,\n",
      "       -0.48039226, -0.10451077,  0.81777815, -0.10769444, -0.23909433,\n",
      "        0.55691969,  1.54558889, -0.40883595, -0.2252932 , -0.13207645,\n",
      "        0.12080512,  0.61629045, -0.16401511,  0.15140472, -0.20329836,\n",
      "       -0.49637498,  0.17052188,  0.50004951, -0.25533526, -0.00312647,\n",
      "       -0.3276324 ,  1.20209046,  0.73044694, -0.18987258,  0.02697566,\n",
      "       -0.76705283, -0.54958244,  0.12265434, -1.00841198, -0.65218248,\n",
      "       -0.47347763, -0.13534087, -0.21855304, -0.18301331, -0.34492673,\n",
      "        0.422457  , -0.09090523, -0.7893016 ,  0.08178118, -0.04245901,\n",
      "       -0.96105335, -0.57490403,  0.06922443,  0.16118826,  0.0380691 ,\n",
      "       -0.21841382, -0.11764474,  0.70337259,  0.41997474, -0.10648571]), array([ 1.82710621e-01, -9.92691390e-02, -1.82687281e-01,  8.57733399e-02,\n",
      "       -5.27510216e-02, -1.58282112e-01, -2.01976065e-01, -4.30242119e-01,\n",
      "       -2.65735163e-01,  1.95239193e-01,  8.43639348e-01,  9.12465440e-03,\n",
      "        6.03133383e-01,  9.95492583e-02, -1.65839537e-01, -1.13768329e-01,\n",
      "       -3.13773832e-02,  1.00211137e-01,  5.56129813e-02, -9.46868481e-02,\n",
      "        5.00656277e-01, -6.77419803e-02, -5.70905737e-01,  8.47146472e-02,\n",
      "        1.13002215e-01, -5.56933384e-01, -1.99501482e-01, -1.46090832e-01,\n",
      "        6.49798627e-01,  9.58700776e-02,  6.28396029e-02, -6.90634617e-03,\n",
      "        8.30608602e-01,  7.06155891e-01,  4.60450047e-02,  7.37927301e-02,\n",
      "       -3.22529988e-01, -8.52238416e-02,  9.66508452e-02, -9.23633246e-02,\n",
      "        8.46948739e-01, -1.01516013e-01, -1.83936670e-01, -7.73547660e-01,\n",
      "        5.24907877e-01,  4.85482138e-01,  1.28620745e-01,  5.23054408e-01,\n",
      "       -1.20504694e-01, -3.21939885e-02, -4.12631221e-01,  4.39961245e-01,\n",
      "        3.28444343e-01,  1.64832119e-01, -5.79070234e-02,  9.56496809e-01,\n",
      "       -7.36918658e-02, -3.97886340e-01, -3.97228413e-03,  3.24751239e-01,\n",
      "        9.61973997e-01,  3.08981914e-02,  7.39470187e-02, -1.91223229e-01,\n",
      "       -1.28667974e-01,  1.27637871e-01,  3.41906202e-02, -6.00913150e-02,\n",
      "       -1.67267761e-02, -4.52124874e-02, -1.09558359e-01, -1.85940984e-01,\n",
      "       -1.40655447e-01, -1.62014666e-01, -3.17355845e-01,  5.72351452e-04,\n",
      "       -9.67041704e-02,  3.94947643e-02,  6.45059158e-02,  8.66613901e-01,\n",
      "        1.10391404e+00, -2.65529243e-03,  8.39101717e-02,  8.96482060e-01,\n",
      "       -5.76817285e-02, -8.29644848e-03, -2.08729124e-01, -3.65489837e-03,\n",
      "       -1.61254018e-01,  4.36521398e-01,  3.95292730e-01,  2.07176205e-01,\n",
      "        1.61061174e-01, -1.50073311e-01, -3.46914242e-01,  9.94723473e-03,\n",
      "       -7.52683251e-02, -1.37993363e-01, -8.83747572e-01,  5.93670280e-02]), array([-0.88520226])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nnclf = MLPClassifier(hidden_layer_sizes = [100, 100], solver='lbfgs',\n",
    "                     random_state = 0).fit(X_train, y_train)\n",
    "\n",
    "# hidden_layer_sizes ->  Neste caso temos 2 camadas ocultas com 100 neurônios em cada camada. \n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy  on training set: {:.2f}'\n",
    "     .format(nnclf.score(X_train, y_train)))\n",
    "print('Accuracy  on test set: {:.2f}'\n",
    "     .format(nnclf.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print('The current loss computed with the loss function ',nnclf.loss_)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('The number of iterations the solver has ran. ',nnclf.n_iter_)\n",
    "\n",
    "print(\"\\n\")\n",
    "print('The ith element in the list represents the bias vector corresponding to layer i + 1. ',nnclf.intercepts_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construindo o modelo com duas camadas com regularização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao  adicionar mais camadas ocultas, com muitas unidades ocultas.Pode-se ver que o número de pesos, ou coeficientes de modelo, para estimar uma rede neural pode aumentar rapidamente.\n",
    "A rede neurai passam a ter muitos milhares de pesos para estimar.\n",
    "\n",
    "Podemos <b>controlar a complexidade desse modelo</b>, adicionando uma penalidade de regularização L2 nos pesos. A regularização L2 <b>penaliza modelos</b> que possuem uma grande soma de quadrados de todos os valores de peso. Pesos próximos de zero evitam problema de paralisia da rede.\n",
    "\n",
    "> A regularização L2 é uma das técnicas usadas para se evitar ou minimizar o\n",
    "impacto do overfitting, recomendada principalmente para conjuntos de dados limitado\n",
    "ou quando não podemos aumentar significativamente o número de camadas do\n",
    "modelo de rede. Sabe-se que, utilizando redes com muitas camadas ou dispondo de\n",
    "um conjunto grande de dados, a chance de se obter sucesso com o modelo aumenta.\n",
    "A regularização L2 consiste em adicionar à função de custo uma regularização aos\n",
    "pesos (por meio da soma dos quadrados dos pesos), evitando poucos valores altos\n",
    "nos parâmetros (PONTI; COSTA, 2017).\n",
    "\n",
    "\n",
    "O parâmetro de regularização para MLPs é chamado alpha. E no scikit-learn, ele é definido como um valor pequeno por padrão, como 0,0001, que fornece um pouco de regularização.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Quando alfa é pequeno, os limites de decisão são muito mais complexos e variáveis. E o excesso de classificação do classificador, como podemos ver na pontuação muito alta do conjunto de treinamento e na baixa pontuação do teste do modelo <b>nnclf</b>. Por outro lado, o modelo abaixo <b>nnclf2</b> usa valor de alfa  5.0. E essa configuração resulta em limites de decisão muito mais suaves, enquanto captura a estrutura global dos dados. E essa maior simplicidade permite generalizar muito melhor, e não se ajustar demais ao conjunto de treinamento. E isso é evidente a partir da pontuação do teste muito mais alta, neste caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  on training set: 0.92\n",
      "Accuracy  on test set: 0.88\n",
      "\n",
      "\n",
      "The current loss computed with the loss function  0.5324949737554309\n",
      "\n",
      "\n",
      "The number of iterations the solver has ran.  522\n",
      "\n",
      "\n",
      "The ith element in the list represents the bias vector corresponding to layer i + 1.  [array([-0.0406744 , -0.18545266,  0.18117017,  0.06610735, -0.28288216,\n",
      "       -0.25859999, -1.41332198, -0.18025247, -0.04586384,  0.22537047,\n",
      "        0.64427723,  0.09663517,  0.21149758,  0.15543835,  0.22360627,\n",
      "        0.1935859 ,  0.10419136, -0.05740477,  0.15910801, -0.17120477,\n",
      "        0.0880858 ,  0.42155118, -0.1953809 , -0.01744011,  0.29119772,\n",
      "       -0.3845912 , -0.06254842, -0.04000038, -0.00509854, -0.00811541,\n",
      "       -0.05330639, -0.08532776, -0.02706262, -0.10198236, -0.13438373,\n",
      "        0.36820112,  0.4457969 ,  0.09236985,  0.11745354,  0.01311029,\n",
      "        0.05139354,  0.2175667 , -0.01611614,  0.1222396 , -0.04724502,\n",
      "       -0.08494503,  0.29418932,  0.07772506, -0.15736152, -0.21769282,\n",
      "       -0.24292054,  0.08823233,  0.19815249, -0.10769444,  0.0374736 ,\n",
      "        0.08828711,  0.36619608,  0.31075039, -0.37476866, -0.1143578 ,\n",
      "        0.0575397 ,  0.38106688, -0.16401511, -0.11005178, -0.1984824 ,\n",
      "        0.43133557,  0.21095838,  0.13396255, -0.12027566,  0.1721711 ,\n",
      "       -0.10658569, -0.0829668 ,  0.08580668, -0.18987258,  0.03434837,\n",
      "       -0.03688125, -0.08715956,  0.11974098, -0.05461452, -0.32323672,\n",
      "       -0.22289241, -0.13534087,  0.35791209, -0.06691156, -0.19030304,\n",
      "        0.17379636,  0.17035573,  0.00759339,  0.04820632,  0.0883526 ,\n",
      "       -0.16860442, -0.28117049,  0.1925461 , -0.22742512,  0.03719039,\n",
      "        0.35056201, -0.11764474,  0.2762269 , -0.02205857, -0.10648571]), array([-0.23137191, -0.02884918, -0.08502268,  0.01164447, -0.08015398,\n",
      "       -0.15828211, -0.04642083,  0.25545789,  0.14309079,  0.10664065,\n",
      "        0.80103829,  0.3367509 ,  0.51146137, -0.11041854, -0.11209653,\n",
      "       -0.11376833, -0.02812022,  0.0822903 ,  0.00624085,  0.2586003 ,\n",
      "        0.0052657 , -0.08583484, -0.14749458,  0.82948572,  0.05521692,\n",
      "       -0.13084914, -0.10312514, -0.14609083,  0.38728414,  0.75713221,\n",
      "        0.20185943,  1.11145455,  0.39047062, -0.25429324, -0.06391322,\n",
      "        0.05507516,  0.06186039,  0.06192814,  0.0348266 ,  0.14735023,\n",
      "        0.54809576, -0.08373203, -0.12896934, -0.46934225, -0.19392566,\n",
      "       -0.26571101,  0.14193693, -0.13330679, -0.12050469,  0.44611954,\n",
      "       -0.12168666,  0.07751524,  0.01741393, -0.12239399,  0.06683937,\n",
      "        0.74501908,  0.09956015,  0.60404653,  0.27284325, -0.05390207,\n",
      "       -0.39387333, -0.09908591,  0.09234489,  0.01415282,  0.09401066,\n",
      "        0.12220923,  0.27514842, -0.21855824, -0.0185142 , -0.0969298 ,\n",
      "       -0.06930421, -0.14893763, -0.14065545, -0.25134568, -0.17592698,\n",
      "       -0.06170106, -0.09670417, -0.06736501, -0.00348933,  0.1425755 ,\n",
      "        0.60182062, -0.07743725, -0.19125288,  0.65114534,  0.12351784,\n",
      "        0.10136036, -0.20308939, -0.05278234, -0.16483354, -0.0298059 ,\n",
      "        0.16100001,  0.10881313,  0.25943968, -0.02441644, -0.16897996,\n",
      "       -0.13635845, -0.07536635, -0.13928229, -0.27344357, -0.03246411]), array([-0.56339636])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "nnclf2 = MLPClassifier(hidden_layer_sizes = [100, 100], \n",
    "                      solver='lbfgs',\n",
    "                      alpha = 5.0,\n",
    "                      max_iter = 700,\n",
    "                       \n",
    "                     random_state = 0).fit(X_train, y_train)\n",
    "\n",
    "# alpha: Penalidade L2\n",
    "\n",
    "# max_iter: Número máximo de iterações. O solucionador itera até a convergência \n",
    "# ou este número de iterações. Para solucionadores estocásticos\n",
    "# (‘sgd’, ‘adam’), observe que isso determina o \n",
    "# número de épocas (quantas vezes cada ponto de dados será usado), não o número de etapas de gradiente.\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy  on training set: {:.2f}'\n",
    "     .format(nnclf2.score(X_train, y_train)))\n",
    "print('Accuracy  on test set: {:.2f}'\n",
    "     .format(nnclf2.score(X_test, y_test)))\n",
    "\n",
    "print(\"\\n\")\n",
    "print('The current loss computed with the loss function ',nnclf2.loss_)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('The number of iterations the solver has ran. ',nnclf2.n_iter_)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print('The ith element in the list represents the bias vector corresponding to layer i + 1. ',nnclf2.intercepts_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
